{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea 1:** EDA y modelos bayesianos\n",
    "## **Grupo 5** \n",
    "## **Integrantes:** \n",
    " * Diego Irarrazaval\n",
    " * Pablo Paredes\n",
    " * Tomas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1:  Carga y limpieza de datos.\n",
    "### P1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:05.812793Z",
     "start_time": "2020-05-14T04:18:04.987869Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`files_raw`, `files_estadisticas` y `files_asignacion` son listas que contienen las direcciones donde se encuentran los .csv a leer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:06.304004Z",
     "start_time": "2020-05-14T04:18:05.814738Z"
    }
   },
   "outputs": [],
   "source": [
    "files_raw = glob.glob('data/raw/**/*.csv', recursive = True)\n",
    "files_estadisticas = glob.glob('data/estadisticas_upz/*.csv')\n",
    "files_asignacion = glob.glob('data/asignacion_upz/*.csv')\n",
    "\n",
    "data_raw = ([pd.read_csv(dir) for dir in files_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del DataFrame y reporte de archivos furnished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:08.214800Z",
     "start_time": "2020-05-14T04:18:06.306002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 4 datos de archivos furnished que no estan en all\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creamos un data frame 'furnished', el cual tendrá dos columnas\n",
    "1) 'url' para hacer el merge finalmente y obtener el data frame requerido\n",
    "2) 'furnished' para contar cuantos datos están en archivos furnished y no en archivos all\n",
    "'''\n",
    "\n",
    "data_all = []\n",
    "data_fur = []\n",
    "\n",
    "for i in [0,2,4,6,8]:\n",
    "    \n",
    "    df1 = pd.read_csv(files_raw[i])\n",
    "    df2 = pd.read_csv(files_raw[i+1])\n",
    "    \n",
    "    data_all.append(df1)\n",
    "    data_fur.append(df2)\n",
    "    \n",
    "df_all = pd.concat(data_all)\n",
    "df_fur = pd.concat(data_fur)\n",
    "    \n",
    "f1 = pd.merge(df_all, df_fur, how='outer', on='url', indicator='furnished')\n",
    "furnished = f1[['url', 'furnished']].copy()\n",
    "\n",
    "furnished.drop_duplicates(inplace = True)\n",
    "furnished.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se reportan si hay datos de archivos furnished que no estén en all \n",
    "\n",
    "print('Hay '+ str(len(furnished[furnished['furnished'] == 'right_only'])) + ' datos de archivos furnished que no estan en all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:08.413806Z",
     "start_time": "2020-05-14T04:18:08.216770Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos el data frame 'data'\n",
    "'''\n",
    "\n",
    "df_aux = pd.concat([df_all, df_fur], ignore_index=True)\n",
    "\n",
    "data = pd.merge(df_aux, furnished, how='inner', on='url')\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se elimina la columna 'furnished' y se quitan los duplicados\n",
    "\n",
    "data.drop('furnished', axis=1, inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T20:25:45.708974Z",
     "start_time": "2020-05-13T20:25:45.704988Z"
    }
   },
   "source": [
    "### P1.2 Limpieza de Columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:09.679075Z",
     "start_time": "2020-05-14T04:18:08.415794Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Limpieza de columnas 'price', 'surface', 'n_rooms', 'n_bath'\n",
    "'''\n",
    "\n",
    "# Columna de precio ('price') tipo float\n",
    "\n",
    "data.price = data['price'].str.replace('.', '')\n",
    "data.price = data['price'].str.strip('$')\n",
    "data.price = data['price'].map(float)\n",
    "\n",
    "# Columna de área ('surface') tipo float\n",
    "\n",
    "data.surface = data['surface'].replace('m2', '', regex=True)\n",
    "data.surface = data['surface'].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:09.817704Z",
     "start_time": "2020-05-14T04:18:09.680847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', 3.0, '5', '4', '2', '1', nan, 5.0, 4.0, '5+', 2.0, 1.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notamos que en la columna de dormitorios ('n_rooms') existe la opción '5+'\n",
    "# por lo que dejaremos esta columna como categórica\n",
    "\n",
    "data.n_rooms.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.016283Z",
     "start_time": "2020-05-14T04:18:09.819690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un diccionario para pasar los datos numéricos de 'n_rooms' a string\n",
    "# y se efectúa el mapeo\n",
    "\n",
    "dic = {3.0: '3', 5.0: '5', 4.0:'4', 2.0:'2', 1.0:'1'}\n",
    "\n",
    "data.n_rooms = data['n_rooms'].replace(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.180746Z",
     "start_time": "2020-05-14T04:18:10.023026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Como habían datos que solo se diferenciaban en la cantidad de dormitorios\n",
    "# por el tipo de dato que eran (float o int), puede haberse creado duplicados. Se borran nuevamente los duplicados\n",
    "# de data\n",
    "\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.263328Z",
     "start_time": "2020-05-14T04:18:10.182707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', 2.0, '1', '4', '3', nan, 3.0, '5', 4.0, 5.0, '5+', 1.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se hace lo mismo con la columnna de cantidad de baños ('n_bath')\n",
    "\n",
    "data.n_bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.469269Z",
     "start_time": "2020-05-14T04:18:10.265343Z"
    }
   },
   "outputs": [],
   "source": [
    "dic = {2.0:'2', 3.0:'3', 4.0:'4', 5.0:'5', 1.0:'1'}\n",
    "\n",
    "data.n_bath.replace(dic)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.544855Z",
     "start_time": "2020-05-14T04:18:10.471210Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Separación de columna property_tipe|rent_type|location en tres columnas\n",
    "con los nombres respectivos\n",
    "\n",
    "'''\n",
    "\n",
    "# Renombramos la columna\n",
    "\n",
    "data.columns = ['PTL', 'price', 'n_rooms', 'n_bath', 'surface', 'details', 'url', 'metrocuadrado_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.732619Z",
     "start_time": "2020-05-14T04:18:10.546562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Casa' 'Apartamento']\n",
      "['Arriendo' 'Venta Y Arriendo']\n"
     ]
    }
   ],
   "source": [
    "# Creamos las columnas y las llenamos\n",
    "\n",
    "col = data['PTL'].str.split(', ', expand=True)\n",
    "\n",
    "meta_col = col[0].str.split(' en ', expand=True)\n",
    "\n",
    "# Nos aseguramos que hayan solo las siguientes opciones:\n",
    "# -> 'Casa', 'Apartamento' para property_type\n",
    "# -> 'Arriendo', 'Venta Y Arriendo' para rent_type\n",
    "\n",
    "print(meta_col[0].unique())\n",
    "print(meta_col[1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.811432Z",
     "start_time": "2020-05-14T04:18:10.734619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Formamos las nuevas columnas 'property_type', 'rent_type', 'location'\n",
    "\n",
    "data['property_type'] = meta_col[0] \n",
    "data['rent_type'] = meta_col[1]\n",
    "data['location'] = col[1]\n",
    "\n",
    "# y retiramos la columna PTL\n",
    "\n",
    "data.drop('PTL', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.953442Z",
     "start_time": "2020-05-14T04:18:10.813089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalmente quitamos la ciudad de 'location'\n",
    "\n",
    "loc = col[1].str.split(' Bogotá', expand=True)\n",
    "data.location = loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T00:56:17.669646Z",
     "start_time": "2020-05-14T00:56:17.643679Z"
    }
   },
   "source": [
    "### P1.3 Precio por metro cuadrado y Cantidad de garages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.389470Z",
     "start_time": "2020-05-14T04:18:10.955051Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Agregamos una columna que represente el precio por metro cuadrado 'price_per_m2'\n",
    "\n",
    "'''\n",
    "\n",
    "data['price_per_m2'] = data['price']/data['surface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.659586Z",
     "start_time": "2020-05-14T04:18:11.392310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Obtenemos la cantidad de garajes y lo agregamos como columna también 'cant_garajes'\n",
    "\n",
    "'''\n",
    "\n",
    "garajes_list = data.url.str.split('-garajes', expand=True)\n",
    "garajes_num = garajes_list[0].str.rsplit('-', n=1, expand=True)\n",
    "\n",
    "# indices que tienen urls con info de la cantidad de garajes\n",
    "ind = garajes_list[1].index[garajes_list[1].isna() == False]\n",
    "\n",
    "# generación de nueva columna para después asignarla a la data\n",
    "garajes_list[2] = np.nan\n",
    "garajes_list[2].loc[ind] = garajes_num[1].loc[ind]\n",
    "\n",
    "# agregación de la cantidad de garajes a la data (nan si no hay info)\n",
    "data['cant_garajes'] = garajes_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T02:22:05.234063Z",
     "start_time": "2020-05-14T02:22:05.206424Z"
    }
   },
   "source": [
    "### P1.4 Clasificación Tipo de Producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.723221Z",
     "start_time": "2020-05-14T04:18:11.661866Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos una nueva columna 'clasif_prod_type' donde se representará la clasificación\n",
    "de la vivienda con dígitos del 1 al 8 de acuerdo al enunciado\n",
    "\n",
    "'''\n",
    "\n",
    "data['clasif_prod_type'] = np.nan\n",
    "\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 80) & (data.surface < 120)] = 1\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 120) & (data.surface < 180)] = 2\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 180) & (data.surface < 240)] = 3\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 240) & (data.surface < 360)] = 4\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 360) & (data.surface < 460)] = 5\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 40) & (data.surface < 60)] = 6\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 60) & (data.surface < 80)] = 7\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 80) & (data.surface < 120)] = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T02:38:15.663253Z",
     "start_time": "2020-05-14T02:38:15.633563Z"
    }
   },
   "source": [
    "### P1.5 Obtención del código UPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.802744Z",
     "start_time": "2020-05-14T04:18:11.724221Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Se carga el archivo y se guarda en un dataframe data_upz\n",
    "Luego, se realiza el merge para obtener el código para cada barrio\n",
    "\n",
    "'''\n",
    "\n",
    "# Se guarda la base de datos en un data frame\n",
    "data_upz = pd.read_csv(files_asignacion[0], usecols = ['UPlCodigo', 'pro_location', 'UPlArea'])\n",
    "\n",
    "# Se deja todo en minuscula para poder hacer el merge correctamente\n",
    "data_upz.pro_location = data_upz.pro_location.map(str).map(lambda s: s.lower())\n",
    "data.location = data.location.map(lambda s: s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.974600Z",
     "start_time": "2020-05-14T04:18:11.803742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 2059 datos no se les puede asignar código UPZ\n",
      "lo cual es 11.195693545756075% de los datos\n"
     ]
    }
   ],
   "source": [
    "#Se realiza el merge y se reportan cuantos datos no fueron asignados con código UPZ\n",
    "\n",
    "data_merge = pd.merge(data, data_upz, left_on='location', right_on='pro_location', how='left')\n",
    "\n",
    "print('A ' + str(sum(data_merge.UPlCodigo.isna())) + ' datos no se les puede asignar código UPZ')\n",
    "print('lo cual es ' + str(sum(data_merge.UPlCodigo.isna())/len(data)*100) + '% de los datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.044238Z",
     "start_time": "2020-05-14T04:18:11.976582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos la columna 'UPZ' en data y le asignamos el código UPZ obtenido en data_merge\n",
    "\n",
    "data['UPZ'] = data_merge['UPlCodigo']\n",
    "data['UPZ_area'] = data_merge['UPlArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.6 Fusión de datos con código UPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.167936Z",
     "start_time": "2020-05-14T04:18:12.049016Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Se cargan los datos en distintos data frames, para después hacerles merge con data\n",
    "Luego, se crea una columna de densidad poblacional para cada código UTZ\n",
    "\n",
    "'''\n",
    "\n",
    "# Se cargan los datos en data frames respectivamente\n",
    "\n",
    "data_pobl = pd.read_csv(files_estadisticas[0])\n",
    "data_inseg = pd.read_csv(files_estadisticas[1])\n",
    "data_verde = pd.read_csv(files_estadisticas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.255661Z",
     "start_time": "2020-05-14T04:18:12.170692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se quitan las columnas innecesarias de data_pobl y data_inseg\n",
    "\n",
    "data_pobl.drop(['Unnamed: 0', 'nomupz'], axis=1, inplace=True)\n",
    "data_inseg.drop(['Unnamed: 0', 'UPlNombre2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.368191Z",
     "start_time": "2020-05-14T04:18:12.264637Z"
    }
   },
   "outputs": [],
   "source": [
    "# En data_verde se tiene que al código UPZ viene solo el número\n",
    "# por lo tanto, hay que transformarlo al formato UPZ + número para poder hacer el merge correctamente\n",
    "\n",
    "col = data_verde.cod_upz.map(int).map(str)\n",
    "col_upz = 'UPZ' + col\n",
    "\n",
    "data_verde.cod_upz = col_upz\n",
    "\n",
    "# Se eliminan las columnas innecesarias\n",
    "data_verde.drop(['Unnamed: 0', 'upz'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.700467Z",
     "start_time": "2020-05-14T04:18:12.370166Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se realiza el merge, eliminando después las columnas innecesarias\n",
    "\n",
    "data = pd.merge(data, data_pobl, left_on='UPZ', right_on='upz', how='left')\n",
    "data.drop('upz', axis=1, inplace=True)\n",
    "data = pd.merge(data, data_inseg, left_on='UPZ', right_on='UPlCodigo', how='left')\n",
    "data.drop('UPlCodigo', axis=1, inplace=True)\n",
    "data = pd.merge(data, data_verde, left_on='UPZ', right_on='cod_upz', how='left')\n",
    "data.drop('cod_upz', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:21:21.225400Z",
     "start_time": "2020-05-14T04:21:21.220386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalmente, se crea la columna de densidad de población para cada código UTZ ('UTZ_density')\n",
    "\n",
    "data['UTZ_density'] = data.personas/data.UPZ_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. EDA\n",
    "### P2.1 Creacion de `estilo()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "#se crea diccionario que dará los valores a setear por defecto en el notebook\n",
    "custom = {\n",
    "    \"font.size\": 12,\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"xtick.labelsize\": 18,\n",
    "    \"ytick.labelsize\": 18,\n",
    "    \"legend.fontsize\": 20,\n",
    "    \"axes.linewidth\": 1.25,\n",
    "    \"grid.linewidth\": 1,\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"lines.markersize\": 6,\n",
    "    \"patch.linewidth\": 1,\n",
    "    \"xtick.major.width\": 1.25,\n",
    "    \"ytick.major.width\": 1.25,\n",
    "    \"xtick.minor.width\": 1,\n",
    "    \"ytick.minor.width\": 1,\n",
    "    \"xtick.major.size\": 6,\n",
    "    \"ytick.major.size\": 6,\n",
    "    \"xtick.minor.size\": 4,\n",
    "    \"ytick.minor.size\": 4,\n",
    "    'figure.figsize':(10.,8.),\n",
    "    \"figure.facecolor\": \"white\",\n",
    "    \"axes.labelcolor\": \".15\",\n",
    "    \"xtick.direction\": \"out\",\n",
    "    \"ytick.direction\": \"out\",\n",
    "    \"xtick.color\": \".15\",\n",
    "    \"ytick.color\": \".15\",\n",
    "    \"axes.axisbelow\": True,\n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"text.color\": \".1\",\n",
    "    \"patch.force_edgecolor\": True,\n",
    "    \"image.cmap\": \"rocket\",\n",
    "    \"xtick.top\": False,\n",
    "    \"ytick.right\": False,\n",
    "         }\n",
    "\n",
    "#En las siguiente línea se implementa el diccionario personalizado como default para este notebook en seaborn\n",
    "sb.set(rc=custom)\n",
    "\n",
    "#se escoge una de las paletas que vienen con seaborn \n",
    "#(distinta a la que se usa por defecto) para el resto de notebook.\n",
    "sb.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T20:24:10.037088Z",
     "start_time": "2020-05-16T20:24:10.012330Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "def get_m_N(beta, S_N, X, y):\n",
    "    return beta * S_N.dot(X.T.dot(y))\n",
    "\n",
    "def get_S_N(alpha, beta, X):\n",
    "    sum1 = beta * X.T.dot(X)\n",
    "    n = sum1.shape[0]\n",
    "    sum2 = alpha * np.identity(n)\n",
    "    total_sum = sum1 + sum2\n",
    "    return np.linalg.inv(total_sum)\n",
    "\n",
    "def get_alpha(gamma, m_N):\n",
    "    return gamma / (m_N.T.dot(m_N))\n",
    "\n",
    "def get_beta(N, gamma, y, m_N, X):\n",
    "    to_sum = (y - m_N.dot(X.T)) ** 2\n",
    "    to_inv = to_sum.sum() / (N - gamma)\n",
    "    return 1. / to_inv\n",
    "\n",
    "def get_gamma(lambdas, alpha):\n",
    "    \"\"\"\n",
    "    nos devuelve el gamma pedido\n",
    "    :param lambdas: valores propios necesarios\n",
    "    :param alpha: alpha a usar\n",
    "    :return: gamma que se devuelve\n",
    "    \"\"\"\n",
    "    return np.array([i / (alpha + i) for i in lambdas]).sum()\n",
    "\n",
    "def get_lambdas(beta, X):\n",
    "    \"\"\"\n",
    "    Devuelve los valores propios necesarios\n",
    "    :param beta: beta a usar\n",
    "    :param X: X de entrada\n",
    "    :return: array con lambdas\n",
    "    \"\"\"\n",
    "    M = beta * X.T.dot(X)\n",
    "    return np.linalg.eig(M)[0]\n",
    "\n",
    "def get_cov(beta, X, S_N, x):\n",
    "    pass\n",
    "\n",
    "def convergence(new, old, tol):\n",
    "    test = np.abs(new - old) / old\n",
    "    if test <= tol:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "class RegresionBayesianaEmpirica(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, alpha_0, beta_0, tol=1e-5, maxiter=2000):\n",
    "        self.alpha_0 = alpha_0\n",
    "        self.beta_0 = beta_0\n",
    "        self.tol = tol\n",
    "        self.maxiter = maxiter\n",
    "\n",
    "        self.alpha = None\n",
    "        self.beta = None\n",
    "        self.gamma = None\n",
    "        self.m_N = None\n",
    "        self.S_N = None\n",
    "        self.lambdas = None\n",
    "\n",
    "    def get_posteriori(self, X, y, alpha, beta):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #valores iniciales\n",
    "        N = X.shape[1]\n",
    "        c_lambdas = get_lambdas(self.beta_0, X)\n",
    "        c_alpha = self.alpha_0\n",
    "        c_beta = self.beta_0\n",
    "        c_gamma = get_gamma(c_lambdas, c_alpha)\n",
    "        c_S_N = get_S_N(c_alpha, c_beta, X)\n",
    "        c_m_N = get_m_N(c_beta, c_S_N, X, y)\n",
    "\n",
    "        # while loop\n",
    "        i = 0\n",
    "        while i < self.maxiter:\n",
    "            i += 1\n",
    "\n",
    "            n_lambdas = get_lambdas(c_beta, X)\n",
    "            n_alpha = get_alpha(c_gamma, c_m_N)\n",
    "            n_beta = get_beta(N, c_gamma, y, c_m_N, X)\n",
    "            n_gamma = get_gamma(n_lambdas, n_alpha)\n",
    "            n_S_N = get_S_N(n_alpha, n_beta, X)\n",
    "            n_m_N = get_m_N(n_beta, n_S_N, X, y)\n",
    "\n",
    "            bool_alpha = convergence(n_alpha, c_alpha, self.tol)\n",
    "            bool_beta = convergence(n_beta, c_beta, self.tol)\n",
    "            bool_gamma = convergence(n_gamma, c_gamma, self.tol)\n",
    "\n",
    "            if bool_alpha and bool_beta and bool_gamma:\n",
    "                self.alpha = n_alpha\n",
    "                self.beta = n_beta\n",
    "                self.gamma = n_gamma\n",
    "                self.m_N = n_m_N\n",
    "                self.S_N = n_S_N\n",
    "                self.lambdas = n_lambdas\n",
    "                break\n",
    "\n",
    "            c_alpha = n_alpha.copy()\n",
    "            c_beta = n_beta.copy()\n",
    "            c_gamma = n_gamma.copy()\n",
    "            c_S_N = n_S_N.copy()\n",
    "            c_m_N = n_m_N.copy()\n",
    "\n",
    "        self.alpha = n_alpha\n",
    "        self.beta = n_beta\n",
    "        self.gamma = n_gamma\n",
    "        self.m_N = n_m_N\n",
    "        self.S_N = n_S_N\n",
    "        self.lambdas = n_lambdas\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X, return_std=False):\n",
    "        mu = self.m_N.T.dot(X)\n",
    "        cov = 1 / self.beta + (X.T.dot(self.S_N.dot(X)))\n",
    "\n",
    "        if return_std == True:\n",
    "            return mu, cov\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del modelo con otro dataset:\n",
    "https://www.kaggle.com/aungpyaeap/fish-market/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = pd.read_csv('Fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159 entries, 0 to 158\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Species  159 non-null    object \n",
      " 1   Weight   159 non-null    float64\n",
      " 2   Length1  159 non-null    float64\n",
      " 3   Length2  159 non-null    float64\n",
      " 4   Length3  159 non-null    float64\n",
      " 5   Height   159 non-null    float64\n",
      " 6   Width    159 non-null    float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 8.8+ KB\n"
     ]
    }
   ],
   "source": [
    "fish.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cols =  ['Length1', 'Length2', 'Length3', 'Height', 'Width', 'Species_cat']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "fish['Species'] = fish['Species'].astype('category')\n",
    "fish['Species_cat'] = fish['Species'].cat.codes\n",
    "\n",
    "X_cols = [col for col in fish.columns if col not in ['Weight','Species']]\n",
    "print('X_cols = ', X_cols)\n",
    "X = fish[X_cols]\n",
    "y = fish['Weight']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>Species_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>21.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>10.3458</td>\n",
       "      <td>3.6636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>41.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>12.4888</td>\n",
       "      <td>7.5958</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>16.5170</td>\n",
       "      <td>5.8515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>10.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.9782</td>\n",
       "      <td>1.2852</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>39.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>45.2</td>\n",
       "      <td>11.9328</td>\n",
       "      <td>7.2772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.3680</td>\n",
       "      <td>4.2340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>25.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>7.8204</td>\n",
       "      <td>4.2042</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>14.9544</td>\n",
       "      <td>5.1708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>20.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.7920</td>\n",
       "      <td>3.6240</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>25.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>28.7</td>\n",
       "      <td>8.3230</td>\n",
       "      <td>5.1373</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Length1  Length2  Length3   Height   Width  Species_cat\n",
       "69      21.2     23.0     25.8  10.3458  3.6636            1\n",
       "127     41.1     44.0     46.6  12.4888  7.5958            2\n",
       "27      32.7     36.0     41.5  16.5170  5.8515            0\n",
       "150     10.8     11.3     12.6   1.9782  1.2852            5\n",
       "124     39.8     43.0     45.2  11.9328  7.2772            2\n",
       "..       ...      ...      ...      ...     ...          ...\n",
       "71      24.0     26.0     29.0  11.3680  4.2340            1\n",
       "106     25.9     28.0     29.4   7.8204  4.2042            2\n",
       "14      29.4     32.0     37.2  14.9544  5.1708            0\n",
       "92      20.5     22.5     24.0   6.7920  3.6240            2\n",
       "102     25.2     27.3     28.7   8.3230  5.1373            2\n",
       "\n",
       "[106 rows x 6 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = RegresionBayesianaEmpirica(0.0000001,0.00000001)\n",
    "rg.fit(X_train.values,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim X_test =  53\n",
      "Largo y_pred =  53\n",
      "Largo y_test =  53\n"
     ]
    }
   ],
   "source": [
    "y_pred = rg.predict(X_test.T)\n",
    "print('Dim X_test = ', len(X_test))\n",
    "print('Largo y_pred = ',len(y_pred))\n",
    "print('Largo y_test = ',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = []\n",
    "for x_i in X_test.values:\n",
    "    y_pred_2.append(rg.predict(x_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim X_test =  53\n",
      "Largo y_pred =  53\n",
      "Largo y_test =  53\n"
     ]
    }
   ],
   "source": [
    "print('Dim X_test = ', len(X_test))\n",
    "print('Largo y_pred = ',len(y_pred_2))\n",
    "print('Largo y_test = ',len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183.06365477105246"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test.values, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 =  (53,)\n",
      "2 =  53\n"
     ]
    }
   ],
   "source": [
    "print('1 = ',y_test.shape)\n",
    "print('2 = ', len(y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  78.    13.4  200.   270.   150.  1000.     7.   180.   188.  1250.\n",
      "  650.  1000.   600.   150.   700.   920.  1000.   218.   225.   700.\n",
      "   10.   610.   500.   500.   955.  1100.   170.   270.     6.7    9.9\n",
      "  510.    70.    51.5  567.   340.   120.   160.   120.   145.   820.\n",
      "  720.   500.     7.5  110.   140.    69.   110.   620.   130.    85.\n",
      "  685.   500.   514. ]\n",
      "[277.1412252894834, 187.59758180725154, 483.60075471527153, 396.8085221844063, 343.8964545406357, 583.4631813173436, 160.68476807302943, 386.76151137578347, 370.24287553982555, 837.3953092133263, 528.0863584057921, 610.9194127579165, 506.9776436173961, 311.4318720784748, 551.1022189666548, 603.8502295862168, 655.6297312941126, 400.32394597516236, 361.4315414217972, 521.0600730343481, 180.49746725830272, 528.2901411856956, 495.85064840980226, 489.2508838240757, 603.3930065381716, 649.5127880758772, 352.7275860411787, 404.28866689056713, 148.9562139423957, 180.41135044422356, 636.5638688869014, 260.16292927073573, 244.21808903058363, 686.3475571593308, 418.78774420615, 330.3867673421197, 345.91991902488843, 323.70234290531903, 334.9488611023578, 592.2731718322024, 552.606837730149, 671.2454966701375, 160.08458050137676, 330.0009678481952, 321.2048256936031, 277.851142307083, 315.3286976090095, 541.509562814333, 320.6485476434826, 297.6793283129504, 553.8659195443531, 491.72733599455466, 492.35598345685037]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.values)\n",
    "print(y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
