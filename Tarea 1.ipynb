{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea 1:** EDA y modelos bayesianos\n",
    "## **Grupo 5** \n",
    "## **Integrantes:** \n",
    " * Diego Irarrazaval\n",
    " * Pablo Paredes\n",
    " * Tomas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1:  Carga y limpieza de datos.\n",
    "### P1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:05.812793Z",
     "start_time": "2020-05-14T04:18:04.987869Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`files_raw`, `files_estadisticas` y `files_asignacion` son listas que contienen las direcciones donde se encuentran los .csv a leer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:06.304004Z",
     "start_time": "2020-05-14T04:18:05.814738Z"
    }
   },
   "outputs": [],
   "source": [
    "files_raw = glob.glob('data/raw/**/*.csv', recursive = True)\n",
    "files_estadisticas = glob.glob('data/estadisticas_upz/*.csv')\n",
    "files_asignacion = glob.glob('data/asignacion_upz/*.csv')\n",
    "files_estadisticas.sort()\n",
    "data_raw = ([pd.read_csv(dir) for dir in files_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del DataFrame y reporte de archivos furnished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:08.214800Z",
     "start_time": "2020-05-14T04:18:06.306002Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos un data frame 'furnished', el cual tendrá dos columnas\n",
    "1) 'url' para hacer el merge finalmente y obtener el data frame requerido\n",
    "2) 'furnished' para contar cuantos datos están en archivos furnished y no en archivos all\n",
    "'''\n",
    "\n",
    "data_all = []\n",
    "data_fur = []\n",
    "\n",
    "for i in [0,2,4,6,8]:\n",
    "    \n",
    "    df1 = pd.read_csv(files_raw[i])\n",
    "    df2 = pd.read_csv(files_raw[i+1])\n",
    "    \n",
    "    data_all.append(df1)\n",
    "    data_fur.append(df2)\n",
    "    \n",
    "df_all = pd.concat(data_all)\n",
    "df_fur = pd.concat(data_fur)\n",
    "    \n",
    "f1 = pd.merge(df_all, df_fur, how='outer', on='url', indicator='furnished')\n",
    "furnished = f1[['url', 'furnished']].copy()\n",
    "\n",
    "furnished.drop_duplicates(inplace = True)\n",
    "furnished.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se reportan si hay datos de archivos furnished que no estén en all \n",
    "\n",
    "print('Hay '+ str(len(furnished[furnished['furnished'] == 'right_only'])) + ' datos de archivos furnished que no estan en all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:08.413806Z",
     "start_time": "2020-05-14T04:18:08.216770Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos el data frame 'data'\n",
    "'''\n",
    "\n",
    "df_aux = pd.concat([df_all, df_fur], ignore_index=True)\n",
    "\n",
    "data = pd.merge(df_aux, furnished, how='inner', on='url')\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se elimina la columna 'furnished' y se quitan los duplicados\n",
    "\n",
    "data.drop('furnished', axis=1, inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T20:25:45.708974Z",
     "start_time": "2020-05-13T20:25:45.704988Z"
    }
   },
   "source": [
    "### P1.2 Limpieza de Columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:09.679075Z",
     "start_time": "2020-05-14T04:18:08.415794Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Limpieza de columnas 'price', 'surface', 'n_rooms', 'n_bath'\n",
    "'''\n",
    "\n",
    "# Columna de precio ('price') tipo float\n",
    "\n",
    "data.price = data['price'].str.replace('.', '')\n",
    "data.price = data['price'].str.strip('$')\n",
    "data.price = data['price'].map(float)\n",
    "\n",
    "# Columna de área ('surface') tipo float\n",
    "\n",
    "data.surface = data['surface'].replace('m2', '', regex=True)\n",
    "data.surface = data['surface'].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:09.817704Z",
     "start_time": "2020-05-14T04:18:09.680847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Notamos que en la columna de dormitorios ('n_rooms') existe la opción '5+'\n",
    "# por lo que dejaremos esta columna como categórica\n",
    "\n",
    "data.n_rooms.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.016283Z",
     "start_time": "2020-05-14T04:18:09.819690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un diccionario para pasar los datos numéricos de 'n_rooms' a string\n",
    "# y se efectúa el mapeo\n",
    "\n",
    "dic = {1.0: '1', 2.0:'2', 3.0: '3', 4.0:'4', 5.0:'5', math.nan: '0'}\n",
    "\n",
    "data.n_rooms = data['n_rooms'].replace(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.180746Z",
     "start_time": "2020-05-14T04:18:10.023026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Como habían datos que solo se diferenciaban en la cantidad de dormitorios\n",
    "# por el tipo de dato que eran (float o int), puede haberse creado duplicados. Se borran nuevamente los duplicados\n",
    "# de data\n",
    "\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.n_rooms.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.263328Z",
     "start_time": "2020-05-14T04:18:10.182707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se hace lo mismo con la columnna de cantidad de baños ('n_bath')\n",
    "\n",
    "data.n_bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.469269Z",
     "start_time": "2020-05-14T04:18:10.265343Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "dic = {1.0: '1', 2.0:'2', 3.0: '3', 4.0:'4', 5.0:'5', math.nan: '0'}\n",
    "\n",
    "data.n_bath = data.n_bath.replace(dic)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.n_bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.544855Z",
     "start_time": "2020-05-14T04:18:10.471210Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Separación de columna property_tipe|rent_type|location en tres columnas\n",
    "con los nombres respectivos\n",
    "\n",
    "'''\n",
    "\n",
    "# Renombramos la columna\n",
    "\n",
    "data.columns = ['PTL', 'price', 'n_rooms', 'n_bath', 'surface', 'details', 'url', 'metrocuadrado_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.732619Z",
     "start_time": "2020-05-14T04:18:10.546562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos las columnas y las llenamos\n",
    "\n",
    "col = data['PTL'].str.split(', ', expand=True)\n",
    "\n",
    "meta_col = col[0].str.split(' en ', expand=True)\n",
    "\n",
    "# Nos aseguramos que hayan solo las siguientes opciones:\n",
    "# -> 'Casa', 'Apartamento' para property_type\n",
    "# -> 'Arriendo', 'Venta Y Arriendo' para rent_type\n",
    "\n",
    "print(meta_col[0].unique())\n",
    "print(meta_col[1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.811432Z",
     "start_time": "2020-05-14T04:18:10.734619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Formamos las nuevas columnas 'property_type', 'rent_type', 'location'\n",
    "\n",
    "data['property_type'] = meta_col[0] \n",
    "data['rent_type'] = meta_col[1]\n",
    "data['location'] = col[1]\n",
    "\n",
    "# y retiramos la columna PTL\n",
    "\n",
    "data.drop('PTL', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.953442Z",
     "start_time": "2020-05-14T04:18:10.813089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalmente quitamos la ciudad de 'location'\n",
    "\n",
    "loc = col[1].str.split(' Bogotá', expand=True)\n",
    "data.location = loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T00:56:17.669646Z",
     "start_time": "2020-05-14T00:56:17.643679Z"
    }
   },
   "source": [
    "### P1.3 Precio por metro cuadrado y Cantidad de garages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.389470Z",
     "start_time": "2020-05-14T04:18:10.955051Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Agregamos una columna que represente el precio por metro cuadrado 'price_per_m2'\n",
    "\n",
    "'''\n",
    "\n",
    "data['price_per_m2'] = np.where(data['surface'] <= 0, float('nan'), data['price']/data['surface'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.659586Z",
     "start_time": "2020-05-14T04:18:11.392310Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Obtenemos la cantidad de garajes y lo agregamos como columna también 'cant_garajes'\n",
    "\n",
    "'''\n",
    "\n",
    "garajes_list = data.url.str.split('-garajes', expand=True)\n",
    "garajes_num = garajes_list[0].str.rsplit('-', n=1, expand=True)\n",
    "\n",
    "# indices que tienen urls con info de la cantidad de garajes\n",
    "ind = garajes_list[1].index[garajes_list[1].isna() == False]\n",
    "\n",
    "# generación de nueva columna para después asignarla a la data\n",
    "garajes_list[2] = np.nan\n",
    "garajes_list[2].loc[ind] = garajes_num[1].loc[ind]\n",
    "\n",
    "# agregación de la cantidad de garajes a la data (nan si no hay info)\n",
    "data['cant_garajes'] = garajes_list[2]\n",
    "data['cant_garajes'] = data['cant_garajes'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T02:22:05.234063Z",
     "start_time": "2020-05-14T02:22:05.206424Z"
    }
   },
   "source": [
    "### P1.4 Clasificación Tipo de Producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.723221Z",
     "start_time": "2020-05-14T04:18:11.661866Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos una nueva columna 'clasif_prod_type' donde se representará la clasificación\n",
    "de la vivienda con dígitos del 1 al 8 de acuerdo al enunciado\n",
    "\n",
    "'''\n",
    "\n",
    "data['clasif_prod_type'] = np.nan\n",
    "\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 80) & (data.surface < 120)] = 1\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 120) & (data.surface < 180)] = 2\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 180) & (data.surface < 240)] = 3\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 240) & (data.surface < 360)] = 4\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 360) & (data.surface < 460)] = 5\n",
    "#data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 360)] = 5\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 40) & (data.surface < 60)] = 6\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 60) & (data.surface < 80)] = 7\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 80)& (data.surface < 120)] = 8\n",
    "#data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 80)] = 8 #& (data.surface < 120)] = 8\n",
    "data['clasif_prod_type'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T02:38:15.663253Z",
     "start_time": "2020-05-14T02:38:15.633563Z"
    }
   },
   "source": [
    "### P1.5 Obtención del código UPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.802744Z",
     "start_time": "2020-05-14T04:18:11.724221Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Se carga el archivo y se guarda en un dataframe data_upz\n",
    "Luego, se realiza el merge para obtener el código para cada barrio\n",
    "\n",
    "'''\n",
    "\n",
    "# Se guarda la base de datos en un data frame\n",
    "data_upz = pd.read_csv(files_asignacion[0], usecols = ['UPlCodigo', 'pro_location', 'UPlArea'])\n",
    "\n",
    "# Se deja todo en minuscula para poder hacer el merge correctamente\n",
    "data_upz.pro_location = data_upz.pro_location.map(str).map(lambda s: s.lower())\n",
    "data.location = data.location.map(lambda s: s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.974600Z",
     "start_time": "2020-05-14T04:18:11.803742Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se realiza el merge y se reportan cuantos datos no fueron asignados con código UPZ\n",
    "\n",
    "data_merge = pd.merge(data, data_upz, left_on='location', right_on='pro_location', how='left')\n",
    "\n",
    "print('A ' + str(sum(data_merge.UPlCodigo.isna())) + ' datos no se les puede asignar código UPZ')\n",
    "print('lo cual es ' + str(sum(data_merge.UPlCodigo.isna())/len(data)*100) + '% de los datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.044238Z",
     "start_time": "2020-05-14T04:18:11.976582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos la columna 'UPZ' en data y le asignamos el código UPZ obtenido en data_merge\n",
    "\n",
    "data['UPZ'] = data_merge['UPlCodigo']\n",
    "data['UPZ_area'] = data_merge['UPlArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.6 Fusión de datos con código UPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.167936Z",
     "start_time": "2020-05-14T04:18:12.049016Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Se cargan los datos en distintos data frames, para después hacerles merge con data\n",
    "Luego, se crea una columna de densidad poblacional para cada código UTZ\n",
    "\n",
    "'''\n",
    "\n",
    "# Se cargan los datos en data frames respectivamente\n",
    "\n",
    "data_pobl = pd.read_csv(files_estadisticas[0])\n",
    "data_inseg = pd.read_csv(files_estadisticas[1])\n",
    "data_verde = pd.read_csv(files_estadisticas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pobl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.255661Z",
     "start_time": "2020-05-14T04:18:12.170692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se quitan las columnas innecesarias de data_pobl y data_inseg\n",
    "\n",
    "data_pobl.drop(['Unnamed: 0', 'nomupz'], axis=1, inplace=True)\n",
    "data_inseg.drop(['Unnamed: 0', 'UPlNombre2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.368191Z",
     "start_time": "2020-05-14T04:18:12.264637Z"
    }
   },
   "outputs": [],
   "source": [
    "# En data_verde se tiene que al código UPZ viene solo el número\n",
    "# por lo tanto, hay que transformarlo al formato UPZ + número para poder hacer el merge correctamente\n",
    "\n",
    "col = data_verde.cod_upz.map(int).map(str)\n",
    "col_upz = 'UPZ' + col\n",
    "\n",
    "data_verde.cod_upz = col_upz\n",
    "\n",
    "# Se eliminan las columnas innecesarias\n",
    "data_verde.drop(['Unnamed: 0', 'upz'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.700467Z",
     "start_time": "2020-05-14T04:18:12.370166Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se realiza el merge, eliminando después las columnas innecesarias\n",
    "\n",
    "data = pd.merge(data, data_pobl, left_on='UPZ', right_on='upz', how='left')\n",
    "data.drop('upz', axis=1, inplace=True)\n",
    "data = pd.merge(data, data_inseg, left_on='UPZ', right_on='UPlCodigo', how='left')\n",
    "data.drop('UPlCodigo', axis=1, inplace=True)\n",
    "data = pd.merge(data, data_verde, left_on='UPZ', right_on='cod_upz', how='left')\n",
    "data.drop('cod_upz', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:21:21.225400Z",
     "start_time": "2020-05-14T04:21:21.220386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalmente, se crea la columna de densidad de población para cada código UTZ ('UTZ_density')\n",
    "\n",
    "\n",
    "data['UTZ_density'] =np.where(data.UPZ_area <=0, math.nan, data.personas/data.UPZ_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. EDA\n",
    "### P2.1 Creacion de `estilo()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#se crea diccionario que dará los valores a setear por defecto en el notebook\n",
    "custom = {\n",
    "    \"font.size\": 12,\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"axes.titlesize\": 18,\n",
    "    \"xtick.labelsize\": 18,\n",
    "    \"ytick.labelsize\": 18,\n",
    "    \"legend.fontsize\": 20,\n",
    "    \"axes.linewidth\": 1.25,\n",
    "    \"grid.linewidth\": 1,\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"lines.markersize\": 6,\n",
    "    \"patch.linewidth\": 1,\n",
    "    \"xtick.major.width\": 1.25,\n",
    "    \"ytick.major.width\": 1.25,\n",
    "    \"xtick.minor.width\": 1,\n",
    "    \"ytick.minor.width\": 1,\n",
    "    \"xtick.major.size\": 6,\n",
    "    \"ytick.major.size\": 6,\n",
    "    \"xtick.minor.size\": 4,\n",
    "    \"ytick.minor.size\": 4,\n",
    "    #'figure.figsize':(10.,8.),\n",
    "    \"figure.facecolor\": \"white\",\n",
    "    \"axes.labelcolor\": \".15\",\n",
    "    \"xtick.direction\": \"out\",\n",
    "    \"ytick.direction\": \"out\",\n",
    "    \"xtick.color\": \".15\",\n",
    "    \"ytick.color\": \".15\",\n",
    "    \"axes.axisbelow\": True,\n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"text.color\": \".1\",\n",
    "    \"patch.force_edgecolor\": True,\n",
    "    \"image.cmap\": \"RdBu_r\",\n",
    "    \"xtick.top\": False,\n",
    "    \"ytick.right\": False,\n",
    "         }\n",
    "\n",
    "#En las siguiente línea se implementa el diccionario personalizado como default para este notebook en seaborn\n",
    "sns.set(rc=custom)\n",
    "\n",
    "#se escoge una de las paletas que vienen con seaborn \n",
    "#(distinta a la que se usa por defecto) para el resto de notebook.\n",
    "#sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2.2 Perfilamiento: \n",
    "#### Naturaleza de las variables:\n",
    "Antes del perfilamiento se hara un estudio de la naturaleza de las variables y se observaran algunas columnas \n",
    "para mejor entendimiento de los datos. \n",
    "Adicionalmente a estos estudios, se realizo lo siguiente:\n",
    "```\n",
    "import pandas_profiling as pp\n",
    "pp.ProfileReport(data)\n",
    "\n",
    "profile = data.profile_report(title='Pandas Profiling Report')\n",
    "profile.to_file(output_file=\"output.html\")\n",
    "```\n",
    "No se incluye en el notebook por el tipo de output que genera y debido a que tiene un largo tiempo de ejecucion. \n",
    "\n",
    "En primer lugar, es importante conocer que tipos de datos tienen las variables (o columnas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprender mejor las variables, se visualizan las primeras 5 filas con `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ayudar a entender las variables numericas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupacion por naturaleza:\n",
    "A continuacion, se grafican las variables para entender como se distribuyen. Para esto, separamos las variables categoricas de las numericas. Ademas, debido a que las variables `'details','url','UPZ','location'` tienen muchos valores distintos, se dejaran en una categoria aparte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['numeric', 'categorical','others']\n",
    "\n",
    "categorical = [col for col in data.columns if data[col].dtype == 'O']\n",
    "categorical += set(['clasif_prod_type'])\n",
    "\n",
    "others = ['details','url','UPZ','location']\n",
    "\n",
    "numeric = list(set(data.columns) - set(categorical))\n",
    "\n",
    "for col in others:\n",
    "    categorical.remove(col)\n",
    "\n",
    "mapping = [('numeric', col) for col in numeric]\n",
    "mapping.extend([('categorical', col) for col in categorical])\n",
    "mapping.extend([('others', col) for col in others])\n",
    "'''\n",
    "Se reordenan las columnas del dataframe para que coincidan con el esquema \n",
    "del multi indice\n",
    "'''\n",
    "\n",
    "data = data.reindex(columns = numeric + categorical + others)\n",
    "data[numeric] = data[numeric].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables numericas:  ['personas', 'areas_verdes_perc', 'UPZ_area', 'indice_inseguridad', 'trabajoinfampliado_ninos_5_17_anos_perc', 'adultos_mayores_pobres_perc', 'surface', 'indice_envegecimiento', 'UTZ_density', 'metrocuadrado_index', 'jovenes_14_24_anos_nini_perc', 'jefe_mujer_perc', 'price', 'trabajoinf_ninos_5_17_anos_perc']\n",
      "\n",
      " variables categoricas:  ['n_rooms', 'n_bath', 'property_type', 'rent_type', 'cant_garajes', 'clasif_prod_type']\n",
      "\n",
      " variables others:  ['details', 'url', 'UPZ', 'location']\n"
     ]
    }
   ],
   "source": [
    "print('variables numericas: ', numeric)\n",
    "print('\\n variables categoricas: ', categorical)\n",
    "print('\\n variables others: ', others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar el perfilamiento, veamos la cantidad de valores unicos de las columnas pertenecientes a others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in others:\n",
    "    n = len(data[col].unique())\n",
    "    msg = 'Cantidad de valores unicos de ' + col + ' = ' + str(n)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que las 4 variables mencionadas anteriormente tienen cardinalidad mayor a 100 por lo que intentar graficarlo de la misma forma que se graficaran las variables categoricas no tiene tanto sentido. Lo que se propone para trabajar estas variables es realizar una codificacion para facilitar el analisis y agrupar donde sea necesario. Esto se realizara en particular para la variable `UPZ`. \n",
    "\n",
    "Las variables `details` y `url` se asumiran que no entregan informacion relevante (o nueva) sobre el precio por $metro^2$. Esto debido a que la informacion que estas columnas contiene se almacena en otras variables como el numero de banos o la cantidad de habitaciones, etc... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graficos de distribuciones univariadas de las variables:\n",
    "Para esto, se implementan dos funciones: `plot_numeric_vars` y `plot_categorical_vars`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para graficar Distribuciones univariadas de variables numericas:\n",
    "def plot_numeric_vars(df, columns, title):\n",
    "    '''\n",
    "    Creaciion de graficos de Distribuciones Univariadas, recibe \n",
    "    el dataframe, las columnas a graficar y el 'SuperTitulo'    \n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    columns: list\n",
    "        Lista con los nombres de las columnas de tipo numerico a graficar. \n",
    "        \n",
    "    title: String\n",
    "        Titulo\n",
    "        \n",
    "    Returns: None\n",
    "        Se muestran los graficos\n",
    "    \n",
    "    \n",
    "    Ejemplo de uso: \n",
    "    ------------\n",
    "    \n",
    "    Dado un DataFrame df:\n",
    "    col_a_graficar = ['col1','col2','col3']\n",
    "    \n",
    "    plot_uni_dist(df,col_a_graficar,'Grafico de variables 1, 2, 3')\n",
    "    \n",
    "    '''\n",
    "    sns.set(rc=custom)\n",
    "    nplots = len(columns)\n",
    "    ncols = 3\n",
    "    nrows = int(np.ceil(nplots/ncols))\n",
    "    \n",
    "    # Grilla de subplots\n",
    "    w = ncols * 5\n",
    "    h = nrows * 4\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=[w, h])\n",
    "\n",
    "    #Veamos si se deben remover plot:\n",
    "    if nplots - ncols*nrows > 0:\n",
    "        r = -(nplots - ncols*nrows)\n",
    "        list(map(lambda a : a.remove(), ax[-1,r:]))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    #Ponemos el titulo:\n",
    "    fig.suptitle(title,\n",
    "             fontsize=20,\n",
    "             x=0.5,\n",
    "             y=1.05)\n",
    "    \n",
    "    #Se recorre cada axis, para cada columna del dataframe, se genera un grafico \n",
    "    #distinto en funcion del tipo de dato.\n",
    "    for axis, col in zip(ax.flatten(), columns):\n",
    "        try :\n",
    "            # Graficos para datos numericos\n",
    "            sns.distplot(df[(col)], ax=axis, rug=True)\n",
    "\n",
    "        except RuntimeError:\n",
    "            sns.distplot(df[(col)], ax=axis, rug=True, kde=False)\n",
    "\n",
    "        axis.set_xlabel(col, fontsize=15)\n",
    "\n",
    "    # Se ajusta el espaciado interno entre subplots\n",
    "    w, h = (.4, .4)\n",
    "    plt.subplots_adjust(wspace=w, hspace=h)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para graficar Distribuciones univariadas de variables numericas:\n",
    "def plot_categorical_vars(df, columns, title, order = dict()):\n",
    "    '''\n",
    "    Creaciion de graficos de Distribuciones Univariadas recibe\n",
    "    el dataframe, las columnas a graficar y el 'SuperTitulo'    \n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    columns: list\n",
    "        Lista con los nombres de las columnas de tipo numerico a graficar. \n",
    "        \n",
    "    title: String\n",
    "        Titulo\n",
    "        \n",
    "    order: dict\n",
    "        Diccionario que contiene como llave el nombre de la columna que se desea ordenar \n",
    "        y como valor una lista con las categorias correspondientes a esa columna en el orden \n",
    "        deseado. \n",
    "        \n",
    "    Returns: None\n",
    "        Se muestran los graficos\n",
    "        \n",
    "        \n",
    "    Ejemplo de uso: \n",
    "    -------------\n",
    "    Dado un DataFrame df:\n",
    "    col_a_graficar = ['col1','col2','col3']\n",
    "    cat_order = {\n",
    "         'col1' = ['cat1','cat2','cat3', 'cat4']\n",
    "         'col2' = [i for i in range(1,11)]\n",
    "         'col3' = ['mujer', 'hombre', 'otro']\n",
    "    }\n",
    "    plot_uni_dist(df,col_a_graficar,'Grafico de variables categoricas', cat_order)\n",
    "    -----------------\n",
    "    \n",
    "    Cuando no se incluye un diccionario order, se ordena por defecto. \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    sns.set(rc=custom)\n",
    "    nplots = len(columns)\n",
    "    ncols = 3\n",
    "    nrows = int(np.ceil(nplots/ncols))\n",
    "    \n",
    "    # Grilla de subplots\n",
    "    w = ncols * 5\n",
    "    h = nrows * 4\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=[w, h])\n",
    "\n",
    "    #Veamos si se deben remover plot:\n",
    "    if nplots - ncols*nrows > 0:\n",
    "        r = -(nplots - ncols*nrows)\n",
    "        list(map(lambda a : a.remove(), ax[-1,r:]))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    #Ponemos el titulo:\n",
    "    fig.suptitle(title,\n",
    "             fontsize=20,\n",
    "             x=0.5,\n",
    "             y=1.05)\n",
    "    '''\n",
    "    Se recorre cada axis, para cada columna del dataframe, se genera un grafico \n",
    "    distinto en funcion del tipo de dato.\n",
    "\n",
    "    '''\n",
    "    for axis, col in zip(ax.flatten(), columns):    \n",
    "        # Graficos para datos tipos str\n",
    "        try:\n",
    "            sns.countplot(df[(col)], ax=axis, order = order[col])\n",
    "        except:\n",
    "            sns.countplot(df[(col)], ax=axis)\n",
    "        axis.set_axis_on()\n",
    "        axis.set_title(col, fontsize=15)\n",
    "  \n",
    "    \n",
    "    # Se ajusta el espaciado interno entre subplots\n",
    "    h, w = (.8, .8)\n",
    "    plt.subplots_adjust(wspace=w, hspace=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_numeric_vars(data,numeric,'Grafico variables numericas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, sobresale la distribucion de `metrocuadrado_index`. Es la unica que no contiene grandes concentraciones. A simple vista, se podria aproximar con una distribucion Normal. Por otro lado, las variables `price`, `surface`, `indice_inseguridad` y `price_per_m2` presentan grandes concentraciones en zonas especificas. \n",
    "\n",
    "Para profundizar el analisis, luego de estudiar las distribuciones de las variables categoricas se estudiaran los comportamientos bivariados: relaciones entre variables con _scatterPlot_ y _violinPlot_. \n",
    "\n",
    "A continuacion se muestran las distribuciones de las variables categoricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_order = {'n_rooms': [ '1', '2', '3', '4', '5', '5+'],\n",
    "              'n_bath': [ '1', '2', '3', '4', '5', '5+'],\n",
    "              'property_type': ['Apartamento', 'Casa'],\n",
    "              'rent_type': ['Arriendo', 'Venta Y Arriendo'],\n",
    "              'cant_garajes': ['1', '2', '3', '4', '4+'],\n",
    "              'clasif_prod_type': [i for i in range(1,9)]\n",
    "             }\n",
    "plot_categorical_vars(data,categorical,'Grafico variables categoricas',plot_order)\n",
    "#len(categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "De las distribuciones de las variables categoricas, es posible inferir que la variable `rent_type` no aporta mucha informacion al momento de inferir el precio por metro$^2$. Esto debido a la alta concentracion en uno de los valores. Se puede inferir lo mismo de la variable `property_type`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprender mejor que informacion me aportan las distintas columnas para resolver el problema, es bueno identificar la varible objetivo o _target_ y hacer graficas comparativas con esta.\n",
    "\n",
    "Como la variable _target_ es el precio cuadrado por metro cuadrado, a continuacion se implementa una funcion para Estudiar como se relacionan estas variables. Para las variables categoricas, el tipo de grafico utilizado es el boxplot o el grafico de violin. Para las variables numericas se utiliza el _scatter plot_. Dado el rango de precio por $metro^2$, es importante que exista la opcion de escalar el eje y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin(target, col, order = None, scale = False ,df = data):\n",
    "    '''\n",
    "    Para variables categoricas v/s una variable target. Las variables categoricas deben ser de baja\n",
    "    cardinalidad, sino el grafico no es util.\n",
    "    Genera grafico de violin e histograma con distribucion de la variable a comparar.\n",
    "    Recibe el nombre de la variable objetivo y la variablecon la cual se desea comparar.\n",
    "    \n",
    "    Args:\n",
    "    --------\n",
    "    target: String\n",
    "        Nombre de la columna objetivo (eje y).\n",
    "    col: String \n",
    "        Nombre de la columna que representara el eje x.\n",
    "    scale: Bool\n",
    "        Si se quiere o no escalar el eje y. Util cuando el rango de esta variable es muy grande. \n",
    "        \n",
    "    Returns: None\n",
    "        Muestra en pantalla dos graficos: Violin plot (similar al boxplot) y el histograma de \n",
    "        la variable col.\n",
    "        \n",
    "    Ejemplo de uso:\n",
    "    --------------\n",
    "    plot_violin('price_per_m2','n_rooms')\n",
    "    '''\n",
    "    sns.set(rc=custom)\n",
    "    \n",
    "    # Sirve para fija el tamaño de lasetiquetas del plot\n",
    "    fontdict = {'fontsize':20}\n",
    "\n",
    "    # Estrucutra de figura y axes\n",
    "    fig, ax = plt.subplots(2,1,figsize=[12,13])\n",
    "\n",
    "    # violin plot --> equivalente a catplot(kind = 'violin')\n",
    "    if scale:\n",
    "        sns.violinplot(col,\n",
    "                    y=(target),\n",
    "                    data=df,\n",
    "                    kind='violin',\n",
    "                    ax=ax[0],\n",
    "                    order = order).set_yscale(\"log\")\n",
    "    else:\n",
    "        sns.violinplot(col,\n",
    "            y=(target),\n",
    "            data=df,\n",
    "            kind='violin',\n",
    "            ax=ax[0],\n",
    "            order = order)\n",
    "\n",
    "    sns.countplot(df[col], ax=ax[1], order = order)\n",
    "\n",
    "    ax[0].set_xlabel(col, fontdict)\n",
    "    ax[1].set_xlabel(col, fontdict)\n",
    "\n",
    "    ax[0].set_ylabel(target, fontdict)\n",
    "    title = 'Violin plot ' + col + ' v/s ' + target\n",
    "    ax[0].set_title(title, fontdict)\n",
    "    title_y = \"Frecuencias \" + col\n",
    "    ax[1].set_title(title_y, fontdict)\n",
    "    \n",
    "\n",
    "    h, w = (.3, .1)\n",
    "    plt.subplots_adjust(wspace=w, hspace=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_violin('price_per_m2','n_rooms', order = plot_order['n_rooms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado: \n",
    "\n",
    "Observemos que, debido al rango de la variable `price_per_m2`, es dificil obtener visualizaiones buenas de la relacion entre las variables. Por esto, se acotara en adelante el precio por m2 para que este en el rango [10000, 100000]. Esto solo se realizara para las visualizaciones y el perfilamiento. Por esto se creara un nuevo DataFrame `new_data`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.copy()\n",
    "new_data = new_data[new_data.price_per_m2 < 100000]\n",
    "new_data = new_data[new_data.price_per_m2 > 10000]\n",
    "'''De esta forma tambien es posible eliminar outliers.'''\n",
    "\n",
    "print('Largo original del DataFrame: ',len(data))\n",
    "print('Largo del nuevo DataFrame: ', len(new_data))\n",
    "print('Maximo precio por m2 del nuevo DataFrame: ', max(new_data.price_per_m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos que al eliminar las colas de la variable `price_per_m2` se mantiene el mismo rango intercuartil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "\n",
    "data['price_per_m2_nuevo'] = data['price_per_m2'].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para el calculo del rango intercuartil se deben eliminar los 'nan'.\n",
    "print('Rango intercuartil price_per_m2 data original: ', iqr(data.price_per_m2_nuevo.dropna()))\n",
    "print('Rango intercuartil price_per_m2 nueva data: ', iqr(new_data.price_per_m2))\n",
    "print('Diferencia porcentual entre los rangos intercuartiles: ',\n",
    "      1- iqr(new_data.price_per_m2) / iqr(data.price_per_m2_nuevo.dropna()) )\n",
    "\n",
    "print('='*100 + '\\n' + 'Cantidad de filas eliminadas: ', len(data)- len(new_data))\n",
    "print('Porcentaje de filas eliminadas: ', 1 - len(new_data)/len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Al eliminar los `nan` y realizar el recorte en base a `price_per_m2`, se obtiene una diferencia porcentual del rango intercuartil del $2\\%$, lo cual para efectos del estudio de graficos sera considerado dentro del rango aceptable. \n",
    "\n",
    "Por otro lado, la cantidad de filas que se eliminan corresponden al $2\\%$\n",
    "\n",
    "A continuacion se observa como cambian las distribuciones de las variables `['price','surface','price_per_m2']` luego de aplicar el recorte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_vars(data,['price','surface','price_per_m2'],'Grafico distribucion datos originales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_vars(new_data,['price','surface','price_per_m2'],'Grafico distribucion datos recortados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuamos con los graficos de variables categoricas v/s precio por metro$^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico para cantidad de piezas vs precio por m2\n",
    "plot_violin('price_per_m2','n_rooms', order = plot_order['n_rooms'],scale = False ,df = new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico para cantidad de piezas vs precio por m2\n",
    "plot_violin('price_per_m2','n_bath', df = new_data, order = plot_order['n_bath'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que, aunque muy leve, existe una relacion entre `price_per_m2` y `n_rooms`. En especial si se toman en cuenta solo los valores pertenecientes a [1, 2, 3, 4, 5] Por otro lado, es claro que las propiedades con 1 y 2 dormitorios son las que predominan.\n",
    "\n",
    "La variable `n_bath` tiene un comportamiento similar \n",
    "\n",
    "Observemos ahora como se relaciona la clasificacion de la propiedad v/s el precio por $metro^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_violin('price_per_m2','clasif_prod_type', df = new_data, order = plot_order['clasif_prod_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en la primera imagen correspondiente a los graficos de violin, se observa una leve pendiente positiva: a medida que aumenta el numero correspondiente a la clasificacion del producto, aumenta (aunque levemente) el precio por $metro^2$. Esta variable sera de interes mas adelante porque ademas no presenta una concentracion en una clase particular tan alta como en el caso de `n_rooms`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin('price_per_m2','property_type', df = new_data, order = plot_order['property_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el precio por metro$^2$ de apartamento es algo mas caro que el de las casas. Por otro lado, hay una gran diferencia en la cantidad de casas y apartamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin('price_per_m2','cant_garajes', df= new_data, order = plot_order['cant_garajes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `cant_garajes` tiene un comportamiento muy similar a las variables `n_bath` y `n_rooms`, pero su distribucion esta mas concentrada en 1 y 2.\n",
    "\n",
    "A continuacion se procede a realizar los mismos graficos: variables numericas v/s precio por metro$^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(target, col, reg = True, scale = False, df = data):\n",
    "    '''\n",
    "    Para variables numericas v/s una variable target. \n",
    "    Genera el scatterplot e histograma con distribucion de la variable a comparar.\n",
    "    Recibe el nombre de la variable objetivo y la variablecon la cual se desea comparar.\n",
    "    \n",
    "    Args:\n",
    "    --------\n",
    "    target: String\n",
    "        Nombre de la columna objetivo (eje y).\n",
    "    col: String \n",
    "        Nombre de la columna que representara el eje x.\n",
    "    reg: Bool\n",
    "        Si se incluye o no una regresion lineal sobre los datos.\n",
    "    scale: Bool\n",
    "        Si se quiere o no escalar el eje y. Util cuando el rango de esta variable es muy grande. \n",
    "        \n",
    "    Returns: None\n",
    "        Muestra en pantalla dos graficos: Violin plot (similar al boxplot) y el histograma de \n",
    "        la variable col.\n",
    "        \n",
    "    Ejemplo de uso:\n",
    "    --------------\n",
    "    plot_scatter('price_per_m2','price')\n",
    "    '''\n",
    "    \n",
    "    sns.set(rc=custom)\n",
    "    \n",
    "    # Sirve para fija el tamaño de lasetiquetas del plot\n",
    "    fontdict = {'fontsize':20}\n",
    "\n",
    "    # Estrucutra de figura y axes\n",
    "    fig, ax = plt.subplots(2,1,figsize=[10,10])\n",
    "\n",
    "    # violin plot --> equivalente a catplot(kind = 'violin')\n",
    "    if scale:\n",
    "        if reg:\n",
    "            sns.regplot(x = col,\n",
    "                        y= target,\n",
    "                        data=df,\n",
    "                        ax=ax[0]).set_yscale(\"log\")\n",
    "            title = 'Scatter plot ' + col + ' v/s log(' + target + ') con ajuste lineal.'\n",
    "            ax[0].set_title(title, fontdict,y=1.05)\n",
    "        else:\n",
    "            sns.scatterplot(x = col,\n",
    "                            y=target,\n",
    "                            data=df,\n",
    "                            ax=ax[0]).set_yscale(\"log\")\n",
    "            title = 'Scatter plot ' + col + ' v/s log(' + target + ')'\n",
    "            ax[0].set_title(title, fontdict,y=1.05)\n",
    "    else:\n",
    "        if reg:\n",
    "            sns.regplot(x = col,\n",
    "                        y= target,\n",
    "                        data=df,\n",
    "                        ax=ax[0])\n",
    "            title = 'Scatter plot ' + col + ' v/s ' + target + ' con ajuste lineal.'\n",
    "            ax[0].set_title(title, fontdict,y=1.05)\n",
    "        else:\n",
    "            sns.scatterplot(x = col,\n",
    "                            y=target,\n",
    "                            data=df,\n",
    "                            ax=ax[0])\n",
    "            title = 'Scatter plot ' + col + ' v/s ' + target\n",
    "            ax[0].set_title(title, fontdict ,y=1.05)\n",
    "\n",
    "    sns.distplot(df[col], ax=ax[1])\n",
    "\n",
    "    ax[0].set_xlabel(col, fontdict)\n",
    "    ax[1].set_xlabel(col, fontdict)\n",
    "\n",
    "    ax[0].set_ylabel(target, fontdict)\n",
    "    \n",
    "    title_y = \"Frecuencias \" + col\n",
    "    ax[1].set_title(title_y, fontdict,y=1.05)\n",
    "    \n",
    "\n",
    "    h, w = (.6, .1)\n",
    "    plt.subplots_adjust(wspace=w, hspace=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos que al fijar un rango para `price_per_m2` y eliminar los datos que sobrepasan este rango, cambia notoriamente la distribucion de `price` y de `surface`. \n",
    "\n",
    "A continuacion se muestan los _scatterPlot_ de algunas variables de interes v/s el precio por metro cuadrado. Se observan las variables `metrocuadrado_index`, `indice_envegecimiento`, `UPZ_area`, `UTZ_density` y `jefe_mujer_perc` ya que se observa que son variables poco concentradas. \n",
    "Es importante mencionar que las variables `price` y `surface` no se incluyen en el analisis ya que precio por metro$^2$ se construye a partir de estas dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var_de_interes = ['metrocuadrado_index', 'indice_envegecimiento', 'UPZ_area', 'UTZ_density', 'jefe_mujer_perc']\n",
    "for var in var_de_interes:\n",
    "    plot_scatter('price_per_m2', var, df = new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, se observa una clara relacion lineal entre `metrocuadrado_index` y `price_per_m2`. De igual forma, el ajuste lineal en las variables `jefe_mujer_perc` e `indice_envegecimiento` indican una relacion entre estas y `price_per_m2` pero con una observacion detenida se puede inferir que probablemente no presenten una dependencia lineal entre ellas. De todas formas, debido a que no presentan grandes concentraciones en valores particulares, seguiran siendo de interes mas adelante. \n",
    "\n",
    "### Codificacion de columnas tipo categorical y string:\n",
    "Como se menciono anteriormente, hay un grupo de variables que no se estudio. Estas corresponden a `details`, `url`, `UPZ`, `location`. A continuacion se realizara un estudio breve de `UPZ` y `location`. Para esto, se codificaran las distintas etiquetas como numeros para que sea mas facil realizar graficos. El funcionamiento del _LabelEncoder_ se muestra a continuacion:\n",
    "\n",
    "```python\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "LabelEncoder()\n",
    "list(le.classes_)\n",
    "['amsterdam', 'paris', 'tokyo']\n",
    "le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
    "array([2, 2, 1]...)\n",
    "list(le.inverse_transform([2, 2, 1]))\n",
    "['tokyo', 'tokyo', 'paris']\n",
    "```\n",
    "\n",
    "[Fuente ejemplo y documentacion LabelEncoder sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codificacion de UPZ\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "new_data.UPZ = new_data['UPZ'].astype('str')\n",
    "\n",
    "le_UPZ = preprocessing.LabelEncoder()\n",
    "le_UPZ.fit(new_data.UPZ.unique())\n",
    "\n",
    "UPZ_code = le_UPZ.classes_\n",
    "new_data['UPZ_cat'] = le_UPZ.transform(new_data.UPZ)\n",
    "\n",
    "print('='*20 + '   Codificacion UPZ   ' + '='*20)\n",
    "print(UPZ_code)\n",
    "print(le_UPZ.inverse_transform([0,0,1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codificacion de location:\n",
    "le_location = preprocessing.LabelEncoder()\n",
    "le_location.fit(new_data.location.unique())\n",
    "\n",
    "location_code = le_location.classes_\n",
    "new_data['location_cat'] = le_location.transform(new_data.location)\n",
    "\n",
    "print('\\n'*2 + '='*20 + '   Codificacion Location   ' + '='*20)\n",
    "print('Location code: ', location_code[25:30])\n",
    "print(le_location.inverse_transform([123,23,435,4,56]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codificacion property_type:\n",
    "le_pptype = preprocessing.LabelEncoder()\n",
    "le_pptype.fit(new_data.property_type.unique())\n",
    "\n",
    "pptype_code = le_pptype.classes_\n",
    "new_data['property_type_cat'] = le_pptype.transform(new_data.property_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter('price_per_m2', 'UPZ_cat', reg = False ,df = new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter('price_per_m2', 'location_cat', df = new_data, reg = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiar comportamiento de las variables `location_cat` y `UPZ_cat` a partir de los graficos no tiene mucho sentido dado que estos representan la codificacion de la variable real. Esto se realizo para facilidad de estudio de correlacion de las variables. \n",
    "\n",
    "#### Perfilamiento Bivariado:\n",
    "Para comenzar el perfilamiento bivariado se emplean visualizaciones a pares. De esta forma podemos observar las relaciones entre las distintas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interes_para_pairplot = ['price_per_m2', 'metrocuadrado_index', 'indice_envegecimiento', 'UPZ_area', 'UTZ_density', \n",
    "           'jefe_mujer_perc', 'clasif_prod_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = new_data[interes_para_pairplot], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vista, la variable que mas llama la atencion como se distribuye es `metrocuadrado_index`. Esta sera de interes en adelante como _feature_ para el regresor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos faltantes:\n",
    "Antes de continuar, se debe realizar un correcto tratamiento de los datos faltantes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa en primer lugar que todas las columnas que contienen informacion proveniente de los datos en `estadisticas_upz` y en `asignacion_upz` contienen la misma cantidad de datos faltantes. El tratamiento de estos datos faltantes se debe hacer luego de la separacion de datos en conjuntos de _train_ y _test_. Para efectos de las visualizacion y extraccion de caracteristicas se reemplazaran en este momento con el promedio de cada columna. \n",
    "\n",
    "Por otro lado, se observa que la columna `clasif_prod_type` tiene una alta cantidad de `nan`. Esto se debe a que hay propiedades que no se encuentran en ninguna de las clasificaciones especificadas en el enunciado. De todas formas, como esta variable se genera a partir de `property_type` y de `surface`, se eliminara esta columna para evitar eliminar 2538 filas (corresponden al 15% de los datos).\n",
    "\n",
    "Es importante mencionar que la columna `cant_garajes` no contiene `nan` debido a que cuando se contruyo, en las filas donde no habia informacion se asume que era porque la cantidad de garajes es $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop(['clasif_prod_type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_nan = ['jefe_mujer_perc', 'personas', 'indice_inseguridad', 'jovenes_14_24_anos_nini_perc', 'UTZ_density',\n",
    "                 'trabajoinf_ninos_5_17_anos_perc', 'adultos_mayores_pobres_perc',\n",
    "                 'trabajoinfampliado_ninos_5_17_anos_perc', 'indice_envegecimiento', 'areas_verdes_perc', \n",
    "                 'UPZ_area']\n",
    "for col in cols_with_nan:\n",
    "    new_data[col] = new_data[col].fillna(new_data[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recategorizar UPZ:\n",
    "Para realizar la recategorizacion de `UPZ` se utilizo k-means con distinta cantidad de clusters y para elegir con que  cantidad se va a recategorizar, se busca la maxima correlacion de esta nueva variable con `price_per_m2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libreria a utilizar:\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#preparacion de los datos para utilizar k-means:\n",
    "new_data = new_data[~new_data.isin([np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como todas las variables categoricas o str se transformaron a numericas, podemos hacer lo siguiente\n",
    "numeric_new = [col for col in new_data.columns if new_data[col].dtype == 'int32' or new_data[col].dtype == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "def get_cluster(k):\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(new_data[numeric_new])\n",
    "\n",
    "\n",
    "    new_data['k_means']=kmeanModel.predict(new_data[numeric_new])\n",
    "    \n",
    "    corr, _ = pearsonr(new_data['price_per_m2'], new_data['k_means'])\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = {}\n",
    "for i in range(3,6):\n",
    "    corr[i] = get_cluster(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a lo obtenido anteriormente, nos quedaremos con una agrupacion de UPZ en base a k-means con 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos la nueva colummna llamada k-means:\n",
    "get_cluster(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16,8))\n",
    "\n",
    "axes[0].scatter(new_data['price_per_m2'], new_data['metrocuadrado_index'], c=new_data['UPZ_cat'])\n",
    "axes[1].scatter(new_data['price_per_m2'], new_data['metrocuadrado_index'], c=new_data['k_means'], cmap=plt.cm.Set1)\n",
    "axes[0].set_title('UPZ original', fontsize=18)\n",
    "axes[1].set_title('UPZ agrupado por K-means (5 clusters)', fontsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los graficos se ve como se relacionan las categorias UPZ originales (codigo de color de la grafica izquierda) con las nuevas obtenidas. \n",
    "\n",
    "\n",
    "### Relaciones entre variables:\n",
    "Para entender como se relacionan las variables entre ellas, se trabajara principalmente con la matriz de correlacion (y el mapa de calor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos la matriz de correlacion\n",
    "corrmat = new_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlaciones muy positivas\n",
    "cols = corrmat.nlargest(15, 'price_per_m2')['price_per_m2'].index \n",
    "print('Variables mas correlacionadas con price_per_m2: ' + '\\n' + '-'*100)\n",
    "corrmat[cols].nlargest(7,cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa en primer lugar que la variable `metrocuadrado_indice` nos aporta mucha informacion sobre `price_per_m2`. Por otro lado, se vuelve a comprobar que la agrupacion creada para `UPZ`, `k_means`, aporta informacion valiosa para la variable _target_, de hecho tiene un indice de correlacion mayor que la variable `UPZ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 = corrmat.nsmallest(5,'price_per_m2')['price_per_m2'].index\n",
    "corrmat[cols2].nsmallest(5, cols2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se muestra el mapa de calor de las variables con correlacion mas alta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.corrcoef(new_data[cols].values.T) \n",
    "f, ax = plt.subplots(figsize =(12, 10)) \n",
    "  \n",
    "sns.heatmap(cm, ax = ax, cmap =\"YlGnBu\", \n",
    "            linewidths = 0.1, yticklabels = cols.values,  \n",
    "                              xticklabels = cols.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de eliminacion de outliers:\n",
    "A continuacion se muestra como se distribuyenen los outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para el calculo del rango intercuartil se deben eliminar los 'nan'.\n",
    "print('Rango intercuartil price_per_m2 data original: ', iqr(data.price_per_m2_nuevo.dropna()))\n",
    "print('Rango intercuartil price_per_m2 nueva data: ', iqr(new_data.price_per_m2))\n",
    "print('Diferencia porcentual entre los rangos intercuartiles: ',\n",
    "      1- iqr(new_data.price_per_m2) / iqr(data.price_per_m2_nuevo.dropna()) )\n",
    "\n",
    "print('='*100 + '\\n' + 'Cantidad de filas eliminadas: ', len(data)- len(new_data))\n",
    "print('Porcentaje de filas eliminadas: ', 1 - len(new_data)/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.copy()\n",
    "new_data = new_data[new_data.price_per_m2 < 100000]\n",
    "new_data = new_data[new_data.price_per_m2 > 10000]\n",
    "'''De esta forma tambien es posible eliminar outliers.'''\n",
    "\n",
    "print('Largo original del DataFrame: ',len(data))\n",
    "print('Largo del nuevo DataFrame: ', len(new_data))\n",
    "print('Maximo precio por m2 del nuevo DataFrame: ', max(new_data.price_per_m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data[data.price_per_m2 > 100000]\n",
    "df2 = data[data.price_per_m2<10000]\n",
    "frames = [df1, df2]\n",
    "result = pd.concat(frames)\n",
    "\n",
    "\n",
    "result.UPZ = result['UPZ'].astype('str')\n",
    "\n",
    "le_UPZ_res = preprocessing.LabelEncoder()\n",
    "le_UPZ_res.fit(result.UPZ.unique())\n",
    "\n",
    "UPZ_code_res = le_UPZ_res.classes_\n",
    "result['UPZ_cat'] = le_UPZ_res.transform(result.UPZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.countplot(result['property_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(result['UPZ_cat'], rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(result['clasif_prod_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection:\n",
    "En base a las matrices de correlacion y a las variables generadas, las columnas elegidas para la regresion son:\n",
    "`[metrocuadrado_index, jefe_mujer_perc, price, indice_envegecimiento, k_means, property_type_cat, surface, location_cat, jovenes_14_24_anos_nini_perc]` \n",
    "\n",
    "Para comprobar que nuestra eleccion no sea mala, se corroborara con el metodo `SelectKBest` de _sklearn_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = ['metrocuadrado_index', 'jefe_mujer_perc', 'price', 'indice_envegecimiento',\n",
    "                 'k_means', 'property_type_cat', 'surface', 'location_cat', 'jovenes_14_24_anos_nini_perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X_cols = [col for col in new_data.columns if col != 'price_per_m2']\n",
    "\n",
    "data_X = new_data.dropna()\n",
    "\n",
    "data_Y = data_X.price_per_m2\n",
    "\n",
    "data_col = [col for col in numeric if col != 'price_per_m2']\n",
    "data_X = data_X[data_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit selector\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "selector.fit(data_X, data_Y)\n",
    "\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = selector.get_support(indices=True)\n",
    "features_df_new = data_X.iloc[:,cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_SelectKBest = features_df_new.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
