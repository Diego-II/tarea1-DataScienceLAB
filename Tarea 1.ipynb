{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarea 1:** EDA y modelos bayesianos\n",
    "## **Grupo 5** \n",
    "## **Integrantes:** \n",
    " * Diego Irarrazaval\n",
    " * Pablo Paredes\n",
    " * Tomas Rojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1:  Carga y limpieza de datos.\n",
    "### P1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:05.812793Z",
     "start_time": "2020-05-14T04:18:04.987869Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`files_raw`, `files_estadisticas` y `files_asignacion` son listas que contienen las direcciones donde se encuentran los .csv a leer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:06.304004Z",
     "start_time": "2020-05-14T04:18:05.814738Z"
    }
   },
   "outputs": [],
   "source": [
    "files_raw = glob.glob('data/raw/**/*.csv', recursive = True)\n",
    "files_estadisticas = glob.glob('data/estadisticas_upz/*.csv')\n",
    "files_asignacion = glob.glob('data/asignacion_upz/*.csv')\n",
    "\n",
    "data_raw = ([pd.read_csv(dir) for dir in files_raw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del DataFrame y reporte de archivos furnished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:08.214800Z",
     "start_time": "2020-05-14T04:18:06.306002Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos un data frame 'furnished', el cual tendrá dos columnas\n",
    "1) 'url' para hacer el merge finalmente y obtener el data frame requerido\n",
    "2) 'furnished' para contar cuantos datos están en archivos furnished y no en archivos all\n",
    "'''\n",
    "\n",
    "data_all = []\n",
    "data_fur = []\n",
    "\n",
    "for i in [0,2,4,6,8]:\n",
    "    \n",
    "    df1 = pd.read_csv(files_raw[i])\n",
    "    df2 = pd.read_csv(files_raw[i+1])\n",
    "    \n",
    "    data_all.append(df1)\n",
    "    data_fur.append(df2)\n",
    "    \n",
    "df_all = pd.concat(data_all)\n",
    "df_fur = pd.concat(data_fur)\n",
    "    \n",
    "f1 = pd.merge(df_all, df_fur, how='outer', on='url', indicator='furnished')\n",
    "furnished = f1[['url', 'furnished']].copy()\n",
    "\n",
    "furnished.drop_duplicates(inplace = True)\n",
    "furnished.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se reportan si hay datos de archivos furnished que no estén en all \n",
    "\n",
    "print('Hay '+ str(len(furnished[furnished['furnished'] == 'right_only'])) + ' datos de archivos furnished que no estan en all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:08.413806Z",
     "start_time": "2020-05-14T04:18:08.216770Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos el data frame 'data'\n",
    "'''\n",
    "\n",
    "df_aux = pd.concat([df_all, df_fur], ignore_index=True)\n",
    "\n",
    "data = pd.merge(df_aux, furnished, how='inner', on='url')\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se elimina la columna 'furnished' y se quitan los duplicados\n",
    "\n",
    "data.drop('furnished', axis=1, inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T20:25:45.708974Z",
     "start_time": "2020-05-13T20:25:45.704988Z"
    }
   },
   "source": [
    "### P1.2 Limpieza de Columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:09.679075Z",
     "start_time": "2020-05-14T04:18:08.415794Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Limpieza de columnas 'price', 'surface', 'n_rooms', 'n_bath'\n",
    "'''\n",
    "\n",
    "# Columna de precio ('price') tipo float\n",
    "\n",
    "data.price = data['price'].str.replace('.', '')\n",
    "data.price = data['price'].str.strip('$')\n",
    "data.price = data['price'].map(float)\n",
    "\n",
    "# Columna de área ('surface') tipo float\n",
    "\n",
    "data.surface = data['surface'].replace('m2', '', regex=True)\n",
    "data.surface = data['surface'].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:09.817704Z",
     "start_time": "2020-05-14T04:18:09.680847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Notamos que en la columna de dormitorios ('n_rooms') existe la opción '5+'\n",
    "# por lo que dejaremos esta columna como categórica\n",
    "\n",
    "data.n_rooms.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.016283Z",
     "start_time": "2020-05-14T04:18:09.819690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un diccionario para pasar los datos numéricos de 'n_rooms' a string\n",
    "# y se efectúa el mapeo\n",
    "\n",
    "dic = {3.0: '3', 5.0: '5', 4.0:'4', 2.0:'2', 1.0:'1'}\n",
    "\n",
    "data.n_rooms = data['n_rooms'].replace(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.180746Z",
     "start_time": "2020-05-14T04:18:10.023026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Como habían datos que solo se diferenciaban en la cantidad de dormitorios\n",
    "# por el tipo de dato que eran (float o int), puede haberse creado duplicados. Se borran nuevamente los duplicados\n",
    "# de data\n",
    "\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.263328Z",
     "start_time": "2020-05-14T04:18:10.182707Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se hace lo mismo con la columnna de cantidad de baños ('n_bath')\n",
    "\n",
    "data.n_bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.469269Z",
     "start_time": "2020-05-14T04:18:10.265343Z"
    }
   },
   "outputs": [],
   "source": [
    "dic = {2.0:'2', 3.0:'3', 4.0:'4', 5.0:'5', 1.0:'1'}\n",
    "\n",
    "data.n_bath.replace(dic)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.544855Z",
     "start_time": "2020-05-14T04:18:10.471210Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Separación de columna property_tipe|rent_type|location en tres columnas\n",
    "con los nombres respectivos\n",
    "\n",
    "'''\n",
    "\n",
    "# Renombramos la columna\n",
    "\n",
    "data.columns = ['PTL', 'price', 'n_rooms', 'n_bath', 'surface', 'details', 'url', 'metrocuadrado_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.732619Z",
     "start_time": "2020-05-14T04:18:10.546562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos las columnas y las llenamos\n",
    "\n",
    "col = data['PTL'].str.split(', ', expand=True)\n",
    "\n",
    "meta_col = col[0].str.split(' en ', expand=True)\n",
    "\n",
    "# Nos aseguramos que hayan solo las siguientes opciones:\n",
    "# -> 'Casa', 'Apartamento' para property_type\n",
    "# -> 'Arriendo', 'Venta Y Arriendo' para rent_type\n",
    "\n",
    "print(meta_col[0].unique())\n",
    "print(meta_col[1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.811432Z",
     "start_time": "2020-05-14T04:18:10.734619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Formamos las nuevas columnas 'property_type', 'rent_type', 'location'\n",
    "\n",
    "data['property_type'] = meta_col[0] \n",
    "data['rent_type'] = meta_col[1]\n",
    "data['location'] = col[1]\n",
    "\n",
    "# y retiramos la columna PTL\n",
    "\n",
    "data.drop('PTL', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:10.953442Z",
     "start_time": "2020-05-14T04:18:10.813089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalmente quitamos la ciudad de 'location'\n",
    "\n",
    "loc = col[1].str.split(' Bogotá', expand=True)\n",
    "data.location = loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T00:56:17.669646Z",
     "start_time": "2020-05-14T00:56:17.643679Z"
    }
   },
   "source": [
    "### P1.3 Precio por metro cuadrado y Cantidad de garages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.389470Z",
     "start_time": "2020-05-14T04:18:10.955051Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Agregamos una columna que represente el precio por metro cuadrado 'price_per_m2'\n",
    "\n",
    "'''\n",
    "\n",
    "data['price_per_m2'] = data['price']/data['surface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.659586Z",
     "start_time": "2020-05-14T04:18:11.392310Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Obtenemos la cantidad de garajes y lo agregamos como columna también 'cant_garajes'\n",
    "\n",
    "'''\n",
    "\n",
    "garajes_list = data.url.str.split('-garajes', expand=True)\n",
    "garajes_num = garajes_list[0].str.rsplit('-', n=1, expand=True)\n",
    "\n",
    "# indices que tienen urls con info de la cantidad de garajes\n",
    "ind = garajes_list[1].index[garajes_list[1].isna() == False]\n",
    "\n",
    "# generación de nueva columna para después asignarla a la data\n",
    "garajes_list[2] = np.nan\n",
    "garajes_list[2].loc[ind] = garajes_num[1].loc[ind]\n",
    "\n",
    "# agregación de la cantidad de garajes a la data (nan si no hay info)\n",
    "data['cant_garajes'] = garajes_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T02:22:05.234063Z",
     "start_time": "2020-05-14T02:22:05.206424Z"
    }
   },
   "source": [
    "### P1.4 Clasificación Tipo de Producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.723221Z",
     "start_time": "2020-05-14T04:18:11.661866Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creamos una nueva columna 'clasif_prod_type' donde se representará la clasificación\n",
    "de la vivienda con dígitos del 1 al 8 de acuerdo al enunciado\n",
    "\n",
    "'''\n",
    "\n",
    "data['clasif_prod_type'] = np.nan\n",
    "\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 80) & (data.surface < 120)] = 1\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 120) & (data.surface < 180)] = 2\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 180) & (data.surface < 240)] = 3\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 240) & (data.surface < 360)] = 4\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Casa') & (data.surface >= 360) & (data.surface < 460)] = 5\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 40) & (data.surface < 60)] = 6\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 60) & (data.surface < 80)] = 7\n",
    "data.clasif_prod_type.loc[(data.property_type == 'Apartamento') & (data.surface >= 80) & (data.surface < 120)] = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T02:38:15.663253Z",
     "start_time": "2020-05-14T02:38:15.633563Z"
    }
   },
   "source": [
    "### P1.5 Obtención del código UPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.802744Z",
     "start_time": "2020-05-14T04:18:11.724221Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Se carga el archivo y se guarda en un dataframe data_upz\n",
    "Luego, se realiza el merge para obtener el código para cada barrio\n",
    "\n",
    "'''\n",
    "\n",
    "# Se guarda la base de datos en un data frame\n",
    "data_upz = pd.read_csv(files_asignacion[0], usecols = ['UPlCodigo', 'pro_location', 'UPlArea'])\n",
    "\n",
    "# Se deja todo en minuscula para poder hacer el merge correctamente\n",
    "data_upz.pro_location = data_upz.pro_location.map(str).map(lambda s: s.lower())\n",
    "data.location = data.location.map(lambda s: s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:11.974600Z",
     "start_time": "2020-05-14T04:18:11.803742Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se realiza el merge y se reportan cuantos datos no fueron asignados con código UPZ\n",
    "\n",
    "data_merge = pd.merge(data, data_upz, left_on='location', right_on='pro_location', how='left')\n",
    "\n",
    "print('A ' + str(sum(data_merge.UPlCodigo.isna())) + ' datos no se les puede asignar código UPZ')\n",
    "print('lo cual es ' + str(sum(data_merge.UPlCodigo.isna())/len(data)*100) + '% de los datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.044238Z",
     "start_time": "2020-05-14T04:18:11.976582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos la columna 'UPZ' en data y le asignamos el código UPZ obtenido en data_merge\n",
    "\n",
    "data['UPZ'] = data_merge['UPlCodigo']\n",
    "data['UPZ_area'] = data_merge['UPlArea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.6 Fusión de datos con código UPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.167936Z",
     "start_time": "2020-05-14T04:18:12.049016Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Se cargan los datos en distintos data frames, para después hacerles merge con data\n",
    "Luego, se crea una columna de densidad poblacional para cada código UTZ\n",
    "\n",
    "'''\n",
    "\n",
    "# Se cargan los datos en data frames respectivamente\n",
    "\n",
    "data_pobl = pd.read_csv(files_estadisticas[0])\n",
    "data_inseg = pd.read_csv(files_estadisticas[1])\n",
    "data_verde = pd.read_csv(files_estadisticas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.255661Z",
     "start_time": "2020-05-14T04:18:12.170692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se quitan las columnas innecesarias de data_pobl y data_inseg\n",
    "\n",
    "data_pobl.drop(['Unnamed: 0', 'nomupz'], axis=1, inplace=True)\n",
    "data_inseg.drop(['Unnamed: 0', 'UPlNombre2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.368191Z",
     "start_time": "2020-05-14T04:18:12.264637Z"
    }
   },
   "outputs": [],
   "source": [
    "# En data_verde se tiene que al código UPZ viene solo el número\n",
    "# por lo tanto, hay que transformarlo al formato UPZ + número para poder hacer el merge correctamente\n",
    "\n",
    "col = data_verde.cod_upz.map(int).map(str)\n",
    "col_upz = 'UPZ' + col\n",
    "\n",
    "data_verde.cod_upz = col_upz\n",
    "\n",
    "# Se eliminan las columnas innecesarias\n",
    "data_verde.drop(['Unnamed: 0', 'upz'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:18:12.700467Z",
     "start_time": "2020-05-14T04:18:12.370166Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se realiza el merge, eliminando después las columnas innecesarias\n",
    "\n",
    "data = pd.merge(data, data_pobl, left_on='UPZ', right_on='upz', how='left')\n",
    "data.drop('upz', axis=1, inplace=True)\n",
    "data = pd.merge(data, data_inseg, left_on='UPZ', right_on='UPlCodigo', how='left')\n",
    "data.drop('UPlCodigo', axis=1, inplace=True)\n",
    "data = pd.merge(data, data_verde, left_on='UPZ', right_on='cod_upz', how='left')\n",
    "data.drop('cod_upz', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T04:21:21.225400Z",
     "start_time": "2020-05-14T04:21:21.220386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalmente, se crea la columna de densidad de población para cada código UTZ ('UTZ_density')\n",
    "\n",
    "data['UTZ_density'] = data.personas/data.UPZ_area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
